# -*- coding: utf-8 -*-
"""TF_creation_Model8.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1r7qO-UXul62UAgfKfb2qo01uaCh-Al3a
"""

#mount the google drive

from google.colab import drive
drive.mount('/content/drive', force_remount = True)

#install tensorflow 

#!pip install tf-object-detection-util
!pip3 install tensorflow==1.15.5

#install tensorflow-object-detection api

!pip install tensorflow-object-detection-api
#be sure to restart the runtime if prompted at this step

#Set the folders for the root directory, image directory where the jpg files reside, and TF output folder to direct the  output from this code
#image_subfolder = "images"

# data_root is the main folder for the images of model 8
data_root = '/content/drive/MyDrive/DAEN690/Iteration203_Model8'

# image_subfolder contains the 1500 jpg images
image_subfolder = "/content/drive/MyDrive/DAEN690/jpg_images_15000"

# tf_folder contains the tf records outputs for the images
tf_folder = "/content/drive/MyDrive/DAEN690/Iteration203_Model8/tf_output"

#import the required libraries and set the flags

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import hashlib
import io
import logging
import os

from lxml import etree
import PIL.Image
import tensorflow as tf

from object_detection.utils import dataset_util
from object_detection.utils import label_map_util
import random

#flags = tf.app.flags
#flags.DEFINE_string('data_dir', '/content/drive/MyDrive/DAEN690', 'Root directory to raw PASCAL VOC dataset.')

#flags.DEFINE_string('annotations_dir', 'annotations',
#                   '(Relative) path to annotations directory.')
#flags.DEFINE_string('image_dir', 'images',
#                   '(Relative) path to images directory.')

#flags.DEFINE_string('output_path', '/content/drive/MyDrive/DAEN690/tf_output', 'Path to output TFRecord')
#flags.DEFINE_string('label_map_path', '/content/drive/MyDrive/DAEN690/lung_classes.pbtxt',
#                   'Path to label map proto')
#flags.DEFINE_boolean('ignore_difficult_instances', True, 'Whether to ignore '
#                    'difficult instances')
#FLAGS = flags.FLAGS

# This function helps in generating complete path to the images to be processed for TF Conversion
# Call this function only if image list needs to be autogenerated from the entire set of images within a folder

def create_trainval_list(data_dir):
   trainval_filename = os.path.abspath(os.path.join(data_dir,"trainval.txt"))
   trainval = open(os.path.abspath(trainval_filename), "w")
   #files = os.listdir(os.path.join(data_dir, FLAGS.image_dir))
   files = os.listdir(os.path.join(data_dir, image_subfolder))

   for f in files:
       #absfile =os.path.abspath(os.path.join(data_dir, FLAGS.image_dir, f))
       absfile =os.path.abspath(os.path.join(data_dir, image_subfolder, f))
       trainval.write(absfile+"\n")
       print(absfile)
   trainval.close()

#This method is called to create the training or validation TF Record by the generate and return one Image TF Record

def dict_to_tf_example(data,
                      dataset_directory,
                      label_map_dict,
                      ignore_difficult_instances=False,
                      image_subdirectory=image_subfolder):
 """Convert XML derived dict to tf.Example proto.
 Notice that this function normalizes the bounding box coordinates provided
 by the raw data.
 Args:
   data: dict holding PASCAL XML fields for a single image
   dataset_directory: Path to root directory holding PASCAL dataset
   label_map_dict: A map from string label names to integers ids.
   ignore_difficult_instances: Whether to skip difficult instances in the
     dataset  (default: False).
   image_subdirectory: String specifying subdirectory within the
     PASCAL dataset directory holding the actual image data.
 Returns:
   example: The converted tf.Example.
 Raises:
   ValueError: if the image pointed to by data['filename'] is not a valid JPEG
 """
 filename = data['filename']

 if filename.find(".jpg") < 0:
     filename = filename+".jpg"
 img_path = os.path.join("",image_subdirectory, filename)
 full_path = os.path.join(dataset_directory, img_path)

 with tf.gfile.GFile(full_path, 'rb') as fid:
   encoded_jpg = fid.read()
 encoded_jpg_io = io.BytesIO(encoded_jpg)
 image = PIL.Image.open(encoded_jpg_io)
 if image.format != 'JPEG':
   raise ValueError('Image format not JPEG')
 key = hashlib.sha256(encoded_jpg).hexdigest()

 width = int(data['size']['width'])
 height = int(data['size']['height'])

 xmin = []
 ymin = []
 xmax = []
 ymax = []
 classes = []
 classes_text = []
 truncated = []
 poses = []
 
 difficult_obj = []
 if 'object' in data:
   for obj in data['object']:
     difficult = bool(int(obj['difficult']))
     if ignore_difficult_instances and difficult:
       continue

     difficult_obj.append(int(difficult))

     xmin.append(float(obj['bndbox']['xmin']) / width)
     ymin.append(float(obj['bndbox']['ymin']) / height)
     xmax.append(float(obj['bndbox']['xmax']) / width)
     ymax.append(float(obj['bndbox']['ymax']) / height)
     classes_text.append(obj['name'].encode('utf8'))
     classes.append(label_map_dict[obj['name']])
     truncated.append(int(obj['truncated']))
     poses.append(obj['pose'].encode('utf8'))

 example = tf.train.Example(features=tf.train.Features(feature={
     'image/height': dataset_util.int64_feature(height),
     'image/width': dataset_util.int64_feature(width),
     'image/filename': dataset_util.bytes_feature(
         data['filename'].encode('utf8')),
     'image/source_id': dataset_util.bytes_feature(
         data['filename'].encode('utf8')),
     'image/key/sha256': dataset_util.bytes_feature(key.encode('utf8')),
     'image/encoded': dataset_util.bytes_feature(encoded_jpg),
     'image/format': dataset_util.bytes_feature('jpeg'.encode('utf8')),
     'image/object/bbox/xmin': dataset_util.float_list_feature(xmin),
     'image/object/bbox/xmax': dataset_util.float_list_feature(xmax),
     'image/object/bbox/ymin': dataset_util.float_list_feature(ymin),
     'image/object/bbox/ymax': dataset_util.float_list_feature(ymax),
     'image/object/class/text': dataset_util.bytes_list_feature(classes_text),
     'image/object/class/label': dataset_util.int64_list_feature(classes),
     'image/object/difficult': dataset_util.int64_list_feature(difficult_obj),
     'image/object/truncated': dataset_util.int64_list_feature(truncated),
     'image/object/view': dataset_util.bytes_list_feature(poses),
 }))
 return example

#For Testing Only
prfxpath = print(os.path.splitext("/path/to/some/file.txt")[0])
prfx = os.path.splitext(os.path.basename("/content/drive/MyDrive/DAEN690/jpg_images/13776ecb39222a7aaace2d9721abebbe.jpg"))[0]
print(prfx)

#Main Function to create all TF Records
#Call once for training and once for validation by setting the examples_list and dataset_type variables

def create_tf(examples_list, annotations_dir, label_map_dict, dataset_type):
  writer = None

  #if not os.path.exists(FLAGS.output_path+"/"+dataset_type):
  #    os.mkdir(FLAGS.output_path+"/"+dataset_type)

  if not os.path.exists(tf_folder + "/" + dataset_type):
    os.mkdir(tf_folder + "/" + dataset_type)

  j = 0
  for idx, example in enumerate(examples_list):

    print(example)

    #if idx % 100 == 0:
    logging.info('On image %d of %d', idx, len(examples_list))
    print('On image %d of %d', idx, len(examples_list))
    #print((FLAGS.output_path + "/tf_training_" + str(j) + ".record"))

    prfx = os.path.splitext(os.path.basename(example))[0]

    #writer = tf.python_io.TFRecordWriter(FLAGS.output_path + "/"+dataset_type+"/tf_training_" + str(j) + ".record")
    #writer = tf.python_io.TFRecordWriter(tf_folder + "/"+dataset_type + "/" + "tf_" + dataset_type + str(j) + ".tfrecord")
    writer = tf.python_io.TFRecordWriter(tf_folder + "/"+dataset_type + "/" + prfx + ".tfrecord")

    path = os.path.join(annotations_dir, os.path.basename(example).replace(".jpg", '.xml'))

    print(path)

    with tf.gfile.GFile(path, 'r') as fid:
        xml_str = fid.read()
    xml = etree.fromstring(xml_str)
    data = dataset_util.recursive_parse_xml_to_dict(xml)['annotation']

    #tf_example = dict_to_tf_example(data, FLAGS.data_dir, label_map_dict,
    #                                FLAGS.ignore_difficult_instances)
    tf_example = dict_to_tf_example(data, data_root + '/', label_map_dict, False)

    writer.write(tf_example.SerializeToString())
    writer.close()
    j = j + 1

#For Test
!ls '/content/drive/MyDrive/DAEN690/Iteration203_Model8/tf_output'

def main():

   #data_dir = FLAGS.data_dir
   #data_dir2 = '/content/drive/MyDrive/DAEN690'

   #When Testing with limited number of files do not let the program create the file list from all the images for you
   #Instead, post your path directly into the file
   #create_trainval_list(data_root)

   label_map_dict = label_map_util.get_label_map_dict(data_root + '/' + 'lung_classes.pbtxt')

   #Instead of using create_trainval_list, we are using the precreated ascii file with image names for Model 8 configuration
   #examples_path = os.path.join(data_root,'trainval.txt')
   examples_path = os.path.join(data_root,'trainval_Model8.txt')

   #annotations_dir = os.path.join(data_dir2, FLAGS.annotations_dir)
   annotations_dir = os.path.join(data_root, "annotations")

   examples_list = dataset_util.read_examples_list(examples_path)
   #print (examples_list)

   random.seed(42)
   random.shuffle(examples_list)
   num_examples = len(examples_list)

   #80% train and 20# validation split
   num_train = int(0.8 * num_examples)
   train_examples = examples_list[:num_train]
   val_examples = examples_list[num_train:]

   #We have setup ready, call the create_tf function for train/val in turn
   #Will take a while depending upon how many files need to be processed :)
   create_tf(train_examples, annotations_dir, label_map_dict, "train")
   create_tf(val_examples, annotations_dir, label_map_dict, "val")

if __name__ == '__main__':
   main()
   #tf.app.run()
